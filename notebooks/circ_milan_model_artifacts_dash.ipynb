{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Requisite Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Standard Library Imports ##############################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from eda_toolkit import ensure_directory, generate_table1\n",
    "\n",
    "######################## Modeling Library Imports ##############################\n",
    "import shap\n",
    "from model_tuner.pickleObjects import loadObjects\n",
    "import model_tuner\n",
    "import eda_toolkit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Add the parent directory to sys.path to access 'functions.py'\n",
    "sys.path.append(os.path.join(os.pardir))\n",
    "\n",
    "from constants import patient_id\n",
    "\n",
    "print(\n",
    "    f\"This project uses: \\n \\n Python {sys.version.split()[0]} \\n model_tuner \"\n",
    "    f\"{model_tuner.__version__} \\n eda_toolkit {eda_toolkit.__version__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths & Read in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your base paths\n",
    "# `base_path`` represents the parent directory of your current working directory\n",
    "base_path = os.path.join(os.pardir)\n",
    "# Go up one level from 'notebooks' to the parent directory, then into the 'data' folder\n",
    "\n",
    "data_path = os.path.join(os.pardir, \"data\")\n",
    "image_path_png = os.path.join(base_path, \"images\", \"png_images\", \"modeling\")\n",
    "image_path_svg = os.path.join(base_path, \"images\", \"svg_images\", \"modeling\")\n",
    "\n",
    "# Use the function to ensure the 'data' directory exists\n",
    "ensure_directory(data_path)\n",
    "ensure_directory(image_path_png)\n",
    "ensure_directory(image_path_svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/processed/\"\n",
    "data_raw = \"../data/\"\n",
    "model_path = \"../mlruns/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(os.path.join(data_raw, \"Laser Circumcision Excel 31.03.2024.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Age (y)\"] >= 18]  # Filter for patients aged 18 and older"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_smote_training\n",
    "model_lr = loadObjects(\n",
    "    os.path.join(\n",
    "        model_path,\n",
    "        \"./452642104975561062/8eab72fdaa134c209521879f18f19d06/artifacts/lr_Bleeding_Edema_Outcome/model.pkl\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# rf_over_training\n",
    "model_rf = loadObjects(\n",
    "    os.path.join(\n",
    "        model_path,\n",
    "        \"./452642104975561062/d18ee7233d0f40ae968e57b596b75ac7/artifacts/rf_Bleeding_Edema_Outcome/model.pkl\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# svm_orig_training\n",
    "model_svm = loadObjects(\n",
    "    os.path.join(\n",
    "        model_path,\n",
    "        \"./452642104975561062/18dc58511b9e45ebaf55308026701c18/artifacts/svm_Bleeding_Edema_Outcome/model.pkl\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_parquet(os.path.join(data_path, \"X.parquet\"))\n",
    "y = pd.read_parquet(os.path.join(data_path, \"y_Bleeding_Edema_Outcome.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"patient_id\"] = X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(patient_id, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_crosstabs = loadObjects(\n",
    "    os.path.join(\n",
    "        data_raw,\n",
    "        \"stacked_crosstabs.pkl\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_cross_surg_tech = loadObjects(\n",
    "    os.path.join(\n",
    "        data_raw,\n",
    "        \"stacked_cross_surg_tech.pkl\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = {**stacked_crosstabs, **stacked_cross_surg_tech}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the full path\n",
    "out_path = os.path.join(data_raw, \"freq_cols.pkl\")\n",
    "\n",
    "# pickle the dict\n",
    "pd.to_pickle(combined, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 1) Extract the **test** pipelines (these don’t resample)\n",
    "pipe_lr = model_lr.test_model\n",
    "pipe_rf = model_rf.test_model\n",
    "pipe_svm = model_svm.test_model\n",
    "\n",
    "# 2) Prepare empty OOF arrays\n",
    "n = len(y)\n",
    "lr_oof = np.zeros(n)\n",
    "rf_oof = np.zeros(n)\n",
    "svm_oof = np.zeros(n)\n",
    "\n",
    "# 3) 10‐fold splitter\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=222)\n",
    "\n",
    "# 4) Manual CV loop\n",
    "for train_idx, test_idx in cv.split(X, y):\n",
    "    X_tr, X_te = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_tr = y.iloc[train_idx]\n",
    "\n",
    "    # fit on the training fold\n",
    "    pipe_lr.fit(X_tr, y_tr)\n",
    "    pipe_rf.fit(X_tr, y_tr)\n",
    "    pipe_svm.fit(X_tr, y_tr)\n",
    "\n",
    "    # predict_proba on the test fold\n",
    "    lr_oof[test_idx] = pipe_lr.predict_proba(X_te)[:, 1]\n",
    "    rf_oof[test_idx] = pipe_rf.predict_proba(X_te)[:, 1]\n",
    "    svm_oof[test_idx] = pipe_svm.predict_proba(X_te)[:, 1]\n",
    "\n",
    "# 5) All arrays are already 1‐D, but just to be safe:\n",
    "lr_oof = lr_oof.ravel()\n",
    "rf_oof = rf_oof.ravel()\n",
    "svm_oof = svm_oof.ravel()\n",
    "true_arr = y.astype(int).to_numpy().ravel()\n",
    "\n",
    "# 6) Build the DataFrame with patient_id as index\n",
    "df_all = pd.DataFrame(\n",
    "    {\n",
    "        \"model_lr\": lr_oof,\n",
    "        \"model_rf\": rf_oof,\n",
    "        \"model_svm\": svm_oof,\n",
    "        \"y_val\": true_arr,\n",
    "    },\n",
    "    index=X.index,  # patient_id\n",
    ")\n",
    "\n",
    "# 7) Reset index into its own column and save\n",
    "out_path = os.path.join(data_raw, \"models.csv\")\n",
    "df_all.reset_index(drop=True).to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved k-fold predictions + true labels to:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bins for age along with labels such that age as a continuous series\n",
    "# can be converted to something more manageable for visualization and analysis\n",
    "bin_ages = [18, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "label_ages = [\n",
    "    \"18-29\",\n",
    "    \"30-39\",\n",
    "    \"40-49\",\n",
    "    \"50-59\",\n",
    "    \"60-69\",\n",
    "    \"70-79\",\n",
    "    \"80-89\",\n",
    "    \"90-99\",\n",
    "]\n",
    "\n",
    "df[\"age_group\"] = pd.cut(\n",
    "    df[\"Age (y)\"],\n",
    "    bins=bin_ages,\n",
    "    labels=label_ages,\n",
    "    right=False,  # <-- include left edge, exclude right\n",
    "    include_lowest=True,  # <-- include the lowest value (e.g. 18)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roc = df[\n",
    "    [\n",
    "        \"age_group\",\n",
    "        \"Cultural / Religious affiliation\",\n",
    "        \"Geographical Origin\",\n",
    "        \"Preoperative drugs (antibiotic)\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roc = df_roc.rename(columns={\"model_svm\": \"Predictions\"})\n",
    "df_roc = df_roc.join(y, how=\"inner\", on=\"patient_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roc.to_csv(os.path.join(data_raw, \"df_preds_roc.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capstone = pd.read_pickle(os.path.join(data_raw, \"freq_cols_capstone.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_circ_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
